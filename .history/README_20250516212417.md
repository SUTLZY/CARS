# CARS: Context-Aware Reinforcement Learning Strategies for Autonomous and Adaptive Systems

## Overview
**CARS** introduces Context-Aware Reinforcement Learning Strategies for Generative AI-Driven Autonomous and Adaptive Systems in Industry 5.0, a novel framework that unites generative modeling with reinforcement learning to enable real-time adaptability and human-centric collaboration in dynamic industrial settings. At its core, CARS employs a Context-Aware Inference Network (CAIN) implemented as a Wasserstein Autoencoder to infer and generate latent context embeddings from raw sensor and operational data, allowing the system to detect and anticipate subtle environmental shifts. These embeddings parameterize a Belief Markov Decision Process (BMDP) which, together with a forward generative dynamics model, synthesizes probabilistic future states. Policy optimization is then carried out via Proximal Policy Optimization (PPO), conditioning actions on both observed states and generated context representations. In extensive simulations of a manufacturing-inspired navigation task with stochastic disturbances, CARS outperforms conventional RL and meta-RL baselines in terms of convergence speed, reward stability, and responsiveness to abrupt changes. The results underscore the promise of integrating generative AI techniques into autonomous and adaptive systems, paving the way for flexible, efficient, and human-augmenting solutions aligned with the vision of Industry 5.0.

**Status:** This project is part of ongoing research. The related paper is currently under submission.

## Table of Contents

- [Key Features](#Features)
- [Architecture](#Architecture)
- [Usage](#usage)
- [Dependencies](#dependencies)
- [Citation](#citation)

## Key Features
- **Context-Aware Inference Network (CAIN):** Dynamically infers latent context shifts from observational data.
- **Belief Markov Decision Process (MDP):** Optimizes decision-making using inferred belief contexts.
- **Forward Dynamics Model:** Improves generalization to unseen dynamics.
- **Proximal Policy Optimization (PPO):** Reinforcement learning algorithm used for policy optimization.
- **Robust Performance:** Demonstrated effectiveness in handling sudden environmental changes.

## Architecture
1. **Context Inference:** CAIN processes observational data to detect environmental shifts.
2. **Belief-Based Decision Making:** The inferred context guides policy adaptation using a belief MDP framework.
3. **Generalization Enhancement:** A forward dynamics model improves adaptability to unseen conditions.
4. **PPO-based Optimization:** Reinforcement learning is performed using PPO for stable policy updates.



## Usage

To run the project, use the following command:

```bash
python driver.py
```

## Dependencies

This project is based on the work presented in the following reference:
```
@InProceedings{cao2022catnipp,
  title = {Context-Aware Attention-based Network for Informative Path Planning},
  author = {Cao, Yuhong and Wang, Yizhuo and Vashisth, Apoorva and Fan, Haolin and Sartoretti, Guillaume},
  booktitle = {6th Annual Conference on Robot Learning},
  year = {2022}
}
```

## Citation

```
@InProceedings{IPP_IRLIDS,
  title     = {CARS:Context-Aware Reinforcement Learning Strategies in Non-Static Environments},
  author    = {Ziyuan Liu, Yan Zhuang},
  year      = {2025}
}
```



## License
This project is licensed under the MIT License.


